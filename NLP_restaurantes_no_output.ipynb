{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Del texto al dato: cómo entienden las máquinas el lenguaje con Python (reseñas de restaurantes)**\n",
        "\n",
        "Las máquinas no entienden el lenguaje como los humanos, sino que **detectan patrones, relaciones y señales numéricas, con los que hacen cálculos más o menos complejos y nos dan unos resultados / diagnósticos basados en probabilidades**.  \n",
        "En este taller veremos paso a paso cómo convertir texto en datos, cómo visualizarlo y cómo analizar su sentimiento, como detectar las palabras más usadas y las más influyentes; a su vez, un conjunto de datos con textos y fechas nos podría ayudar a detectar y visualizar tendencias conversacionales o de opiniones a lo largo del tiempo.\n",
        "\n",
        "Este archivo contiene textos cortos de estilo \"reseñas\" de restaurantes. Además, el código funcionará igual con opiniones, artículos, comentarios de redes sociales, literatura, cartas, encuestas, letras de canciones, conversaciones, etc.\n",
        "\n",
        "Una vez descargada su copia del archivo, el usuario es libre de explorar con sus propios textos, modificando así los texto que encontrará entre comillas (como objetos de tipo *string*) para ver las diferencias de resultados.\n",
        "\n",
        "Usaremos herramientas ampliamente utilizadas en el análisis de lenguaje: **NLTK**, **VADER**, **spaCy**, **TextBlob**, **matplotlib** y **WordCloud**.\n",
        "\n",
        "https://github.com/cristinasprogrammingadventure/PyDay-2025_workshop-Del-Texto-al-Dato_NLP"
      ],
      "metadata": {
        "id": "o5wDu4Ub-mbx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ¿Qué vamos a aprender?\n",
        "\n",
        "Aprenderemos cómo convertir texto en datos medibles, cómo analizar palabras, cómo extraer información útil y cómo los algoritmos estiman el tono o contenido de un texto. Estas son las tareas que realizaremos:\n",
        "\n",
        "1. Cargar texto y limpiarlo.  \n",
        "2. Tokenización: convertir texto en palabras individuales.  \n",
        "3. Eliminar puntuación y stopwords.  \n",
        "4. Obtener frecuencias de palabras y ver las más comunes.  \n",
        "5. Crear nubes de palabras.  \n",
        "6. Hacer análisis de sentimiento (TextBlob, VADER, pysentimiento, etc)\n",
        "7. Visualizar sentimientos con gráficos.  \n",
        "8. Comparación entre textos.  \n",
        "9. Conclusiones y limitaciones del análisis automático.\n",
        "\n"
      ],
      "metadata": {
        "id": "i0TPbE9J-vtQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Textos y librerías\n",
        "\n",
        "Algunas de las librerías específicas que usaremos:\n",
        "\n",
        "- **NLTK**: tokenización y stopwords.  \n",
        "- **TextBlob**: análisis de sentimiento simple.  \n",
        "- **VADER**: análisis de sentimiento optimizado para redes sociales.  \n",
        "- **Matplotlib / Seaborn**: visualización de polaridades, sentimentos y el peso de las palabras   \n",
        "  - **WordCloud**: nubes de palabras.\n",
        "  - **Radar charts de palabras**\n",
        "\n",
        "A continuación cargaremos las librerías y empezaremos con los textos."
      ],
      "metadata": {
        "id": "nmoe3n_j-2Hw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Primer bloque de código didáctico (carga de textos + tokenización)***\n"
      ],
      "metadata": {
        "id": "aqWCj_yi_FOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Librerías básicas\n",
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "\n",
        "# Para análisis de sentimiento\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Para visualización\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Descargar recursos necesarios de NLTK\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download(\"punkt_tab\") # para tokenización en español\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "stopwords_es = stopwords.words(\"spanish\") # Stopwords en español\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rsPADfK1_QFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Textos a analizar (creando un objeto)**\n",
        "\n",
        "- Escribirlos directamente entre comillas\n",
        "- Cargarlos desde un fichero .txt, .csv\n",
        "- Cargarlos desde una URL\n",
        "- Cargarlo haciendo *web scraping*"
      ],
      "metadata": {
        "id": "aDSp2smU_quB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Texto escrito directamente entre comillas\n",
        "\n",
        "texto1 = \"\"\"\n",
        "Volveré ! El servicio es excelente y la comida, deliciosa. El ambiente es agradable. El personal muy atento. Excelente ubicación.\n",
        "Personalmente, me agrada mucho. Sin duda volveré pronto.\n",
        "\"\"\"\n",
        "\n",
        "texto2 = \"\"\"\n",
        "La espera fue larga y la comida llegó fría. El servicio fue descuidado\n",
        "y la experiencia en general bastante decepcionante.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "GyAaS62g_spG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tokenización básica**"
      ],
      "metadata": {
        "id": "Ph8cB0Cy_1Jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def limpiar_y_tokenizar(texto):\n",
        "    texto = texto.lower()\n",
        "    texto = re.sub(r\"[^\\wáéíóúüñ]+\", \" \", texto)\n",
        "    tokens = word_tokenize(texto, language=\"spanish\")\n",
        "    tokens = [t for t in tokens if t not in stopwords_es and t not in string.punctuation]\n",
        "    return tokens\n",
        "\n",
        "tokens1 = limpiar_y_tokenizar(texto1)\n",
        "tokens2 = limpiar_y_tokenizar(texto2)\n",
        "\n",
        "tokens1, tokens2"
      ],
      "metadata": {
        "id": "VXSXt9ekGBKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtener la **frecuencia** de cada *palabra / token* con el ***Counter***\n",
        "\n"
      ],
      "metadata": {
        "id": "smJgFFXNAcS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# si no se hizo en el prncipio, se debería escribir ahora el código -> \"from collections import Counter\"\n",
        "# Llamamos al contador de palabras 'Counter'\n",
        "\n",
        "def frecuencia_palabras(tokens):\n",
        "    return Counter(tokens)\n",
        "\n",
        "freq1 = frecuencia_palabras(tokens1)\n",
        "freq2 = frecuencia_palabras(tokens2)\n",
        "\n",
        "freq1.most_common(10), freq2.most_common(10)\n"
      ],
      "metadata": {
        "id": "hLOfhwPmAIRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualización simple de **frecuencias**"
      ],
      "metadata": {
        "id": "oOQVeIsOAhpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_frecuencias(counter, titulo):\n",
        "    palabras, frecs = zip(*counter.most_common(10))\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.bar(palabras, frecs)\n",
        "    plt.title(titulo)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "plot_frecuencias(freq1, \"Top palabras texto 1\")\n",
        "plot_frecuencias(freq2, \"Top palabras texto 2\")\n"
      ],
      "metadata": {
        "id": "veC_LiK4Ajj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***WordCloud*** para cada texto"
      ],
      "metadata": {
        "id": "9V67J6XgAqjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generar_wordcloud(texto, titulo):\n",
        "    wc = WordCloud(width=800, height=400, background_color=\"white\").generate(texto)\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.imshow(wc, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(titulo)\n",
        "    plt.show()\n",
        "\n",
        "generar_wordcloud(texto1, \"WordCloud - texto 1\")\n",
        "\n"
      ],
      "metadata": {
        "id": "krBgGI5_AsP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generar_wordcloud(texto2, \"WordCloud - texto 2\")"
      ],
      "metadata": {
        "id": "TM-09lBxx36C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observaciones:**\n",
        "\n",
        "- WordCloud **tiene stopwords** porque estás usando el **texto original**\n",
        "\n",
        "- El WordCloud no sabe qué es una stopword, a menos que se las pasemos nosotros.\n",
        "\n",
        "**Solución:**\n",
        "\n",
        "- crear WordCloud sin stopwords, así:"
      ],
      "metadata": {
        "id": "_M_YEWTYNp9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "stopwords_wc = set(STOPWORDS) | set(stopwords_es)\n",
        "\n",
        "def generar_wordcloud_sin_stopwords(texto, titulo):\n",
        "    wc = WordCloud(\n",
        "        width=800,\n",
        "        height=400,\n",
        "        background_color=\"white\",\n",
        "        stopwords=stopwords_wc\n",
        "    ).generate(texto)\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.imshow(wc, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(titulo)\n",
        "    plt.show()\n",
        "\n",
        "generar_wordcloud_sin_stopwords(texto1, \"WordCloud sin stopwords - Texto 1 - reseña restaurante 1\")\n",
        "\n"
      ],
      "metadata": {
        "id": "R_PT7SkZNz3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generar_wordcloud_sin_stopwords(texto2, \"WordCloud sin stopwords - Texto 2 - reseña restaurante 2\")"
      ],
      "metadata": {
        "id": "KyElmqK4xwpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análisis de sentimiento con ***TextBlob***"
      ],
      "metadata": {
        "id": "UCgFc8NOAxNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Polarity - Subjectivity (falta poner)\n",
        "\n",
        "def sentimiento_textblob(texto):\n",
        "    blob = TextBlob(texto)\n",
        "    return blob.sentiment.polarity\n",
        "\n",
        "print(\"Sentimiento texto 1:\", sentimiento_textblob(texto1))\n",
        "print(\"Sentimiento texto 2:\", sentimiento_textblob(texto2))\n"
      ],
      "metadata": {
        "id": "i_oNdv5QA0m9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observaciones:**\n",
        "\n",
        "- TextBlob no sirve para español.\n",
        "\n",
        "- TextBlob solo tiene un modelo de sentimiento para inglés y devuelve valores a veces 'absurdos'"
      ],
      "metadata": {
        "id": "J8JqcX6qKizN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análisis de sentimiento con ***VADER***"
      ],
      "metadata": {
        "id": "2X17OqGBA16m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "sent1 = sia.polarity_scores(texto1)\n",
        "sent2 = sia.polarity_scores(texto2)\n",
        "\n",
        "sent1, sent2\n"
      ],
      "metadata": {
        "id": "0dq7BTYNBAg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Visualización del sentimiento (barras)**"
      ],
      "metadata": {
        "id": "G87uVv6nA8k1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_sentiment_vader(scores, titulo):\n",
        "    labels = list(scores.keys())\n",
        "    vals = list(scores.values())\n",
        "    plt.figure(figsize=(6,3))\n",
        "    plt.bar(labels, vals)\n",
        "    plt.title(titulo)\n",
        "    plt.show()\n",
        "\n",
        "plot_sentiment_vader(sent1, \"Sentimiento VADER - Texto 1 - reseña restaurante 1\")\n",
        "plot_sentiment_vader(sent2, \"Sentimiento VADER - Texto 2 - reseña restaurante 2\")\n"
      ],
      "metadata": {
        "id": "MkvNbLsYA6Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observaciones: reseñas de restaurantes**\n",
        "\n",
        "- texto positivo (opinión ++ sobre restaurante) → compound -0.55   (resultado 'NEGATIVO' -> incorrecto)\n",
        "\n",
        "- texto negativo  (opinión -- sobre restaurante) → compound 0.0     (resultado 'NEUTRO' -> incorrecto)\n",
        "\n",
        "**Causas:**\n",
        "\n",
        "- VADER no funciona bien en español ya que está diseñado para inglés.\n",
        "- El lexicón contiene ~7.500 palabras solo con carga emocional.\n",
        "- Palabras neutras y muchas subjetivas NO aparecen.\n",
        "- En español casi nada coincide, por eso da NO ENCONTRADA."
      ],
      "metadata": {
        "id": "F_dHAygGLUW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CÓDIGO PARA VER PUNTUACIÓN PALABRA POR PALABRA con VADER\n",
        "\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "palabras = [\n",
        "    \"excelente\", \"excellent\", \"larga\", \"long\",\n",
        "    \"servicio\", \"service\", \"atento\", \"attentive\",\n",
        "    \"terrible\", \"deliciosa\", \"delicious\", \"delic\",\n",
        "    \"mala\", \"bad\", \"fría\", \"cold\",\n",
        "    \"decepcionante\", \"disappointing\",\n",
        "    \"pero\", \"but\"\n",
        "]\n",
        "\n",
        "for p in palabras:\n",
        "    if p in analyzer.lexicon:\n",
        "        print(f\"{p:15} → {analyzer.lexicon[p]}\")\n",
        "    else:\n",
        "        print(f\"{p:15} → NO ENCONTRADA EN EL LEXICON\")\n",
        "\n"
      ],
      "metadata": {
        "id": "3v6CFOmxKNfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[p for p in analyzer.lexicon if \"delic\" in p]\n"
      ],
      "metadata": {
        "id": "cBWFMQ5eAxp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(analyzer.lexicon.items())[:100]\n"
      ],
      "metadata": {
        "id": "m1Vd0Xf4Apuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simulación de pipeline"
      ],
      "metadata": {
        "id": "RQIQjr-g2T2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Soluciones posibles**:\n",
        "\n",
        "✔ Opción A : Usar VADER en textos traducidos al inglés\n",
        "\n",
        "- Luego aplicar VADER sobre el texto traducido.\n",
        "- Rápido ya que no requiere entrenamiento\n",
        "\n",
        "✔✔ Opción B — Usar un modelo de sentimiento para español\n",
        "\n",
        "\n",
        "- HuggingFace sentiment-es (modelo entrenado en español)\n",
        "\n",
        "- nlptown/bert-base-multilingual-sentiment\n",
        "\n",
        "- pysentimiento (RobBERT, BERTin, BETO (modelos finetuned))"
      ],
      "metadata": {
        "id": "Q2seZiGZLs9n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analizar los 2 textos con ***pysentimiento***\n",
        "\n",
        "Cómo funciona pysentimiento\n",
        "\n",
        "pysentimiento es un modelo basado en BERT multilingüe (a veces “BETO” para español) ya entrenado para reconocer sentimiento en español.\n",
        "\n",
        "✔️ ¿Qué analiza?\n",
        "\n",
        "\n",
        "las palabras\n",
        "\n",
        "sus relaciones sintácticas\n",
        "\n",
        "su contexto entero (antes y después)\n",
        "\n",
        "patrones de uso típicos en reseñas y comentarios\n",
        "\n",
        "Es decir:\n",
        "no usa diccionarios positivos/negativos como VADER,\n",
        "sino que reconoce patrones gracias a haber sido entrenado con miles de ejemplos reales.\n",
        "\n",
        "✔️ Devuelve\n",
        "\n",
        "Cuando le das un texto, devuelve:\n",
        "\n",
        "output = etiqueta final (POS / NEU / NEG)\n",
        "probas = {probabilidad de POS, NEU, NEG}\n",
        "\n",
        "\n",
        "Ejemplo:\n",
        "\n",
        "AnalyzerOutput(output=POS,\n",
        "               probas={POS: 0.981, NEU: 0.017, NEG: 0.002})\n",
        "\n",
        "✔️ No devuelve un valor 'compound'\n",
        "\n",
        "Porque eso es una creación específica de VADER, no un concepto general.\n",
        "En modelos de clasificación moderna como BERT:\n",
        "\n",
        "la predicción final = la clase con mayor probabilidad\n",
        "\n",
        "la “intensidad” = las probabilidades mismas\n",
        "(p. ej. POS=0.98 → muy positivo)"
      ],
      "metadata": {
        "id": "6BH9T6d1R55T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo con pysentimiento e instalación de esta librería:\n",
        "\n",
        "!pip install pysentimiento\n",
        "from pysentimiento import create_analyzer\n",
        "\n"
      ],
      "metadata": {
        "id": "kTUDnCI3Mj1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n",
        "print(analyzer.predict(texto1))\n",
        "print(analyzer.predict(texto2))"
      ],
      "metadata": {
        "id": "NZ_pToVjioR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "res1 = analyzer.predict(texto1)\n",
        "res2 = analyzer.predict(texto2)\n",
        "\n",
        "res1, res2"
      ],
      "metadata": {
        "id": "s8H5Hyj4RwqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observaciones / resultados:\n",
        "\n",
        "- texto1 -> POS: , NEU: , NEG:\n",
        "\n",
        "- texto2 -> NEG: , NEU: , POS:"
      ],
      "metadata": {
        "id": "yukQkTQNNMiy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gráfico de barras comparando probabilidades de sentimiento"
      ],
      "metadata": {
        "id": "vgWX6BlbRyX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "labels = [\"POS\", \"NEU\", \"NEG\"]\n",
        "\n",
        "probs1 = [res1.probas[\"POS\"], res1.probas[\"NEU\"], res1.probas[\"NEG\"]]\n",
        "probs2 = [res2.probas[\"POS\"], res2.probas[\"NEU\"], res2.probas[\"NEG\"]]\n",
        "\n",
        "x = np.arange(len(labels))  # posiciones\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.bar(x - width/2, probs1, width, label='Texto 1')\n",
        "plt.bar(x + width/2, probs2, width, label='Texto 2')\n",
        "\n",
        "plt.xticks(x, labels)\n",
        "plt.ylabel(\"Probabilidad\")\n",
        "plt.title(\"Comparación de sentimiento (pysentimiento)\")\n",
        "plt.legend()\n",
        "plt.ylim(0,1)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uRd-W70mSKyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pie charts de cada texto"
      ],
      "metadata": {
        "id": "anSn-K9eRyck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pie_sentimiento(result, titulo):\n",
        "    labels = [\"POS\", \"NEU\", \"NEG\"]\n",
        "    sizes = [result.probas[\"POS\"], result.probas[\"NEU\"], result.probas[\"NEG\"]]\n",
        "\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)\n",
        "    plt.title(titulo)\n",
        "    plt.axis('equal')\n",
        "    plt.show()\n",
        "\n",
        "pie_sentimiento(res1, \"Sentimiento – Texto 1\")\n",
        "pie_sentimiento(res2, \"Sentimiento – Texto 2\")\n"
      ],
      "metadata": {
        "id": "_aVZuNJxSZmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### # Pie Chart doble personalizado, más visual\n",
        "\n",
        "- con colores específicos y 30% de transparencia (alpha=0.3)\n",
        "- Cada radar chart por separado como figuras independientes.\n",
        "\n",
        "    POS → verde bosque\n",
        "\n",
        "    NEU → azul claro\n",
        "\n",
        "    NEG → rojo burdeos\n",
        "\n",
        "  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GTO4qit6aI4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Los colores (forestgreen, lightskyblue, darkred) de tipo \"semáforo\"\n",
        "colores = {\n",
        "    \"POS\": \"forestgreen\",\n",
        "    \"NEU\": \"lightskyblue\",\n",
        "    \"NEG\": \"darkred\"\n",
        "}\n",
        "\n",
        "def pie_sentimiento_doble(result1, result2, titles=(\"Texto 1\", \"Texto 2\")):\n",
        "    labels = [\"POS\", \"NEU\", \"NEG\"]\n",
        "\n",
        "    sizes1 = [result1.probas[l] for l in labels]\n",
        "    sizes2 = [result2.probas[l] for l in labels]\n",
        "\n",
        "    # Crear figura con 2 gráficos lado a lado\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14,6))\n",
        "\n",
        "    # -------- PIE 1 --------\n",
        "    wedges1, texts1, autotexts1 = axes[0].pie(\n",
        "        sizes1,\n",
        "        labels=labels,\n",
        "        colors=[colores[l] for l in labels],\n",
        "        autopct=lambda pct: f\"{pct:.1f}%\",\n",
        "        startangle=140,\n",
        "        wedgeprops={'alpha': 0.7}  # % de transparencia\n",
        "    )\n",
        "    axes[0].set_title(titles[0])\n",
        "    axes[0].axis('equal')\n",
        "\n",
        "    # Leyenda externa\n",
        "    axes[0].legend(wedges1, labels, title=\"Sentimiento\", loc=\"upper right\", bbox_to_anchor=(1.3, 1))\n",
        "\n",
        "    # -------- PIE 2 --------\n",
        "    wedges2, texts2, autotexts2 = axes[1].pie(\n",
        "        sizes2,\n",
        "        labels=labels,\n",
        "        colors=[colores[l] for l in labels],\n",
        "        autopct=lambda pct: f\"{pct:.1f}%\",\n",
        "        startangle=140,\n",
        "        wedgeprops={'alpha': 0.7}\n",
        "    )\n",
        "    axes[1].set_title(titles[1])\n",
        "    axes[1].axis('equal')\n",
        "\n",
        "    axes[1].legend(wedges2, labels, title=\"Sentimiento\", loc=\"upper right\", bbox_to_anchor=(1.3, 1))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# --- Llamar función ---\n",
        "pie_sentimiento_doble(res1, res2, titles=(\"Sentimiento – Texto 1\", \"Sentimiento – Texto 2\"))\n"
      ],
      "metadata": {
        "id": "5bKCJDQraMen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Radar Chart (para comparación multiclase)\n",
        "\n",
        "Aquí de momento sólo tenems 3 clases / criterios analizados : \"POS\", \"NEU\", \"NEG\""
      ],
      "metadata": {
        "id": "nN8QNBMXRyq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def radar_chart(res1, res2, labels=[\"POS\", \"NEU\", \"NEG\"]):\n",
        "    # Probabilidades\n",
        "    probs1 = [res1.probas[l] for l in labels]\n",
        "    probs2 = [res2.probas[l] for l in labels]\n",
        "\n",
        "    # Cerrar el círculo\n",
        "    probs1 += probs1[:1]\n",
        "    probs2 += probs2[:1]\n",
        "\n",
        "    # Ángulos\n",
        "    angles = np.linspace(0, 2 * np.pi, len(labels) + 1)\n",
        "\n",
        "    # Radar\n",
        "    fig, ax = plt.subplots(figsize=(6,6), subplot_kw={\"polar\": True})\n",
        "\n",
        "    ax.plot(angles, probs1, linewidth=2)\n",
        "    ax.fill(angles, probs1, alpha=0.25)\n",
        "\n",
        "    ax.plot(angles, probs2, linewidth=2)\n",
        "    ax.fill(angles, probs2, alpha=0.25)\n",
        "\n",
        "    ax.set_xticks(angles[:-1])\n",
        "    ax.set_xticklabels(labels)\n",
        "\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.set_title(\"Radar Chart – Comparación de sentimiento (pysentimiento)\")\n",
        "\n",
        "    plt.legend([\"Texto 1\", \"Texto 2\"], loc=\"upper right\", bbox_to_anchor=(1.3, 1.1))\n",
        "    plt.show()\n",
        "\n",
        "radar_chart(res1, res2)\n"
      ],
      "metadata": {
        "id": "tFdsjysyTeL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mismos colores que en el radar\n",
        "# (no haría falta redefinirlos !)\n",
        "\n",
        "colores = {\n",
        "    \"POS\": \"forestgreen\",\n",
        "    \"NEU\": \"lightskyblue\",\n",
        "    \"NEG\": \"darkred\"\n",
        "}\n",
        "\n",
        "def radar_chart_doble(result1, result2, titles=(\"Texto 1\", \"Texto 2\"), labels=[\"POS\", \"NEU\", \"NEG\"]):\n",
        "    # Preparación de datos\n",
        "    probs1 = [result1.probas[l] for l in labels] + [result1.probas[labels[0]]]\n",
        "    probs2 = [result2.probas[l] for l in labels] + [result2.probas[labels[0]]]\n",
        "\n",
        "    angles = np.linspace(0, 2*np.pi, len(labels) + 1)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14,6), subplot_kw=dict(polar=True))\n",
        "\n",
        "    # --- Gráfico 1 ---\n",
        "    ax = axes[0]\n",
        "    color1 = colores[result1.output]\n",
        "\n",
        "    ax.plot(angles, probs1, linewidth=2, color=color1)\n",
        "    ax.fill(angles, probs1, alpha=0.3, color=color1)\n",
        "\n",
        "    ax.set_xticks(angles[:-1])\n",
        "    ax.set_xticklabels(labels, fontsize=12)\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.set_title(titles[0], fontsize=14, pad=20)\n",
        "\n",
        "    # --- Gráfico 2 ---\n",
        "    ax = axes[1]\n",
        "    color2 = colores[result2.output]\n",
        "\n",
        "    ax.plot(angles, probs2, linewidth=2, color=color2)\n",
        "    ax.fill(angles, probs2, alpha=0.3, color=color2)\n",
        "\n",
        "    ax.set_xticks(angles[:-1])\n",
        "    ax.set_xticklabels(labels, fontsize=12)\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.set_title(titles[1], fontsize=14, pad=20)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# --- Llamar función ---\n",
        "radar_chart_doble(res1, res2, titles=(\"Radar – Texto 1\", \"Radar – Texto 2\"))\n"
      ],
      "metadata": {
        "id": "fkNQmHcoYu4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### spaCy — modelo inglés o español"
      ],
      "metadata": {
        "id": "jai10YL-BJsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")  # Si quieres español: es_core_news_sm\n",
        "\n",
        "doc = nlp(\"The service was excellent and the food was delicious.\")\n",
        "\n",
        "[(token.text, token.pos_) for token in doc]\n"
      ],
      "metadata": {
        "id": "1SPzRLy0BLRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análisis sintáctico y dependencias"
      ],
      "metadata": {
        "id": "R_CCUV8GBNvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "\n",
        "displacy.render(doc, style=\"dep\", jupyter=True)\n"
      ],
      "metadata": {
        "id": "5PajIrjWBSy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracción de entidades con spaCy"
      ],
      "metadata": {
        "id": "yIWFa41BBUrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[(ent.text, ent.label_) for ent in doc.ents]\n"
      ],
      "metadata": {
        "id": "X3stzNBnBYvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparación entre textos (similitud)"
      ],
      "metadata": {
        "id": "Ua5u9_3CBdLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = nlp(texto1)\n",
        "doc2 = nlp(texto2)\n",
        "\n",
        "doc1.similarity(doc2)\n"
      ],
      "metadata": {
        "id": "ujzdh7UcBf4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusiones\n",
        "\n",
        "Hemos visto cómo convertir texto en datos, cómo limpiarlo, visualizarlo y analizar su sentimiento.  \n",
        "También vimos cómo las máquinas interpretan la estructura del lenguaje.\n",
        "\n",
        "Este cuaderno muestra un flujo básico para análisis exploratorio de texto:  \n",
        "desde tokenización y frecuencias hasta sentimiento y relaciones entre textos.\n",
        "\n",
        "Estos métodos son útiles para:\n",
        "- reseñas  \n",
        "- encuestas abiertas  \n",
        "- análisis de redes sociales  \n",
        "- análisis de artículos o noticias  \n",
        "- comparaciones entre documentos  \n"
      ],
      "metadata": {
        "id": "C7XPAg9NBn6t"
      }
    }
  ]
}