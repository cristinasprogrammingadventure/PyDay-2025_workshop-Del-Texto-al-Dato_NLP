{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Del texto al dato: cómo entienden las máquinas el lenguaje humano con Python**\n",
        "\n",
        "**Fichero de experimentación y mejor comprensión del PLN a través de NLTK (Natural Language Toolkit - NLTK) - Vader**\n",
        "\n",
        "Este fichero Jupyter Notebook, es una sub-parte del presente taller de **Procesamiento del lenguage natural (NLP)** a través del **análisis de sentimiento y texto**, para experimentación y **exploración más profunda** con el algorítmo Vader de la biblioteca de Python NLTK a fin de **entender de dónde vienen los números** que llevan al algorítmo a calcular, darnos unos resultados u otros.\n",
        "\n",
        "https://github.com/cristinasprogrammingadventure/PyDay-2025_workshop-Del-Texto-al-Dato_NLP"
      ],
      "metadata": {
        "id": "39eXg-8NlCCo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Librerías básicas (manejo de datos y entorno)"
      ],
      "metadata": {
        "id": "11i6jo1Tm6FY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== LIBRERÍAS BÁSICAS ====\n",
        "\n",
        "import pandas as pd        # manejo de datos en tablas (DataFrames)\n",
        "import numpy as np         # cálculos numéricos y arrays\n",
        "import math\n",
        "import re                  # expresiones regulares (limpieza de texto)\n",
        "import string              # manejo de puntuación\n"
      ],
      "metadata": {
        "id": "l67M99qzldPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Librerías para procesamiento de texto (NLP / análisis de sentimiento)"
      ],
      "metadata": {
        "id": "UKXcIuLpnHL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== LIBRERÍAS DE PROCESAMIENTO DE TEXTO ====\n",
        "\n",
        "######################  NRC Emotion Lexicon\n",
        "# --- NLTK: herramientas clásicas de NLP ---\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from collections import namedtuple, OrderedDict\n",
        "\n",
        "stopwords_es = stopwords.words(\"spanish\")\n"
      ],
      "metadata": {
        "id": "-FUJonLfld4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Librerías para visualización"
      ],
      "metadata": {
        "id": "oW6-cBIgoOQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== LIBRERÍAS DE VISUALIZACIÓN ====\n",
        "\n",
        "import matplotlib.pyplot as plt      # gráficos base\n",
        "import seaborn as sns                # gráficos de alto nivel (opcional)\n",
        "from wordcloud import WordCloud      # nubes de palabras\n",
        "\n",
        "# --- diagramas específicos ---\n",
        "# !pip install matplotlib-venn\n",
        "# from matplotlib_venn import venn2   # comparar vocabulario entre textos\n",
        "\n",
        "# --- estilo gráfico ---\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"Set2\")\n"
      ],
      "metadata": {
        "id": "NgtjVJ7RoOx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SIMULACRO de pipeline paso a paso con NLTK - Vader !!!**\n",
        "\n",
        "Se han creado unas celdas didácticas que muestran\n",
        "\n",
        "**paso a paso cómo VADER procesa** una frase (**tokeniza, busca en el léxico, aplica reglas** — negación, intensificadores, mayúsculas, signos de exclamación—, suma y normaliza con la fórmula compound).\n",
        "\n",
        "La función está pensada para usarla en un Colab Notebook con ***nltk.sentiment.SentimentIntensityAnalyzer***\n",
        "\n",
        "**Explicación de lo que hace:**\n",
        "\n",
        "- Tokeniza la frase con un método simple (palabras y signos).\n",
        "\n",
        "- Busca cada token en analyzer.lexicon (el diccionario VADER real). Si está, toma su score base; si no, base=0.\n",
        "\n",
        "- Aplica reglas didácticas como lo hace Vader:\n",
        "\n",
        "  - Intensificadores (boosters) que multiplican la palabra.\n",
        "\n",
        "  - Negaciones que invierten/atenuan.\n",
        "\n",
        "  - ALL CAPS (mayúsculas) aumentan intensidad.\n",
        "\n",
        "  - Exclamaciones en el texto aumentan intensidad.\n",
        "\n",
        "  - Contraste con “but / pero”: multiplica los elementos posteriores (peso más alto para lo posterior).\n",
        "\n",
        "  - Calcula el adjusted_score por token = base × modifier.\n",
        "\n",
        "  - Suma los adjusted_score y aplica la fórmula del compound para normalizar entre −1 y +1.\n",
        "\n",
        "  - Muestra el **compound** que devuelve **analyzer.polarity_scores(text)** para comparar textos de dferentes tamaños.\n"
      ],
      "metadata": {
        "id": "QD3Hjiti2sNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Código — análisis paso a paso (VADER-like, pero algo más sencillo)**\n",
        "\n",
        "- El código es simplificado: **replica las reglas más relevantes** de VADER para que se vea paso a paso lo que ocurre.\n",
        "\n",
        "- VADER real tiene ajustes y detalles más finos (p. ej. constantes ligeramente distintas, tratamiento más preciso de mayúsculas, puntuación, emoticonos y contracciones).\n",
        "\n",
        "- En español la mayor parte de tokens no aparecen en el lexicon\n",
        "  - found = False para muchas palabras (VADER no es recomendable para español sin traducir)."
      ],
      "metadata": {
        "id": "poOsKdWDtmHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Ejemplos con los textos en español y traducidos al inglés ===\n",
        "\n",
        "texto1 = \"Volveré ! El servicio es excelente y la comida, deliciosa. El ambiente es agradable. El personal muy atento. Excelente ubicación. Personalmente, me agrada mucho. Sin duda volveré pronto.\"\n",
        "texto2 = \"La espera fue larga y la comida llegó fría. El servicio fue descuidado y la experiencia en general bastante decepcionante.\"\n",
        "texto3 = \"I will return! The service is excellent and the food is delicious. The atmosphere is pleasant. The staff is very attentive. Excellent location. Personally, I like it a lot. I will definitely be back soon.\"\n",
        "texto4 = \"OMG !!! The wait was TOO LONG and the food arrived cold. The service was careless and the overall experience was quite disappointing.\"\n",
        "texto5 = \"OMG, OH MY GOD !!! The wait was TOO LONG and the food arrived cold. The service was careless and the overall experience was quite disappointing, but my kids love it.\"  # + parte contrastante \"but my kids love it\"\n"
      ],
      "metadata": {
        "id": "F6YogDus8I0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline simplificado al estilo Vader\n",
        "\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Reglas/recursos didácticos (pequeño subconjunto de intensificadores y negaciones)\n",
        "BOOSTER_DICT = {\n",
        "    \"very\": 1.5, \"extremely\": 2.0, \"absolutely\": 1.8, \"really\": 1.5,\n",
        "    \"quite\": 1.2, \"slightly\": 0.5, \"barely\": 0.5\n",
        "}\n",
        "NEGATE = {\"no\", \"not\", \"never\", \"n't\", \"none\", \"nunca\", \"jamás\", \"sin\"}   # incluimos algunos en español para demo\n",
        "CONTRASTIVE = {\"but\", \"pero\", \"aunque\", \"sin embargo\", \"however\", \"nevertheless\"}\n",
        "\n",
        "# Estructura de salida por token\n",
        "TokenInfo = namedtuple(\"TokenInfo\", [\"token\", \"found\", \"base_score\", \"modifier\", \"adjusted_score\", \"notes\"])\n",
        "\n",
        "def _simple_tokenize(text):\n",
        "    # tokenizador simple: separa por espacios y signos, mantiene palabras\n",
        "    text = text.strip()\n",
        "    # conservar ¡¿? etc? simplificamos\n",
        "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", text, flags=re.UNICODE)\n",
        "    return tokens\n",
        "\n",
        "def compute_compound_from_list(scores):\n",
        "    \"\"\"Aplica la fórmula compound = sum(x) / sqrt(sum(x^2)+15)\"\"\"\n",
        "    sum_x = sum(scores)\n",
        "    sum_x2 = sum([x*x for x in scores])\n",
        "    compound = sum_x / math.sqrt(sum_x2 + 15.0)\n",
        "    # limitar por seguridad\n",
        "    if compound > 1: compound = 1.0\n",
        "    if compound < -1: compound = -1.0\n",
        "    return compound\n",
        "\n",
        "def vader_stepwise(text, analyzer=analyzer, show_details=True):\n",
        "    \"\"\"\n",
        "    Analiza la frase paso a paso con lógica estilo VADER (didáctica, simplificada).\n",
        "    Devuelve: list(TokenInfo), suma, compound_manual, compound_analyzer\n",
        "    \"\"\"\n",
        "    tokens = _simple_tokenize(text)\n",
        "    # lower tokens para lookup, pero conservamos info original\n",
        "    lowered = [t.lower() for t in tokens]\n",
        "\n",
        "    # detectar si hay mayúsculas que sugieran énfasis (más de la mitad de letras del token en mayúscula)\n",
        "    def caps_emphasis(tok):\n",
        "        letters = [c for c in tok if c.isalpha()]\n",
        "        if not letters:\n",
        "            return False\n",
        "        upper_count = sum(1 for c in letters if c.isupper())\n",
        "        return upper_count > 0 and (upper_count / len(letters)) > 0.5\n",
        "\n",
        "    # Recorremos tokens y construimos info\n",
        "    infos = []\n",
        "    for i, tok in enumerate(tokens):\n",
        "        low = lowered[i]\n",
        "        base = None\n",
        "        found = False\n",
        "        notes = []\n",
        "        # buscar en lexicon (vader lexicon está en analyzer.lexicon)\n",
        "        if low in analyzer.lexicon:\n",
        "            base = analyzer.lexicon[low]\n",
        "            found = True\n",
        "            notes.append(\"lexicon\")\n",
        "        else:\n",
        "            # probar lematizar/strip de sufijos simples (didáctico)\n",
        "            # ejemplo: \"delicious\" ok, \"deliciosa\" no → no lo convertimos automáticamente aquí\n",
        "            base = 0.0\n",
        "        # start modifier = 1.0 (sin cambio)\n",
        "        modifier = 1.0\n",
        "\n",
        "        # chequeo de intensificadores en ventana previa (2 tokens previos)\n",
        "        window_start = max(0, i-3)\n",
        "        for j in range(window_start, i):\n",
        "            w = lowered[j]\n",
        "            if w in BOOSTER_DICT:\n",
        "                modifier *= BOOSTER_DICT[w]\n",
        "                notes.append(f\"booster({w})\")\n",
        "\n",
        "        # chequeo de negación en ventana previa (3 tokens)\n",
        "        neg_found = any(w in NEGATE for w in lowered[max(0,i-3):i])\n",
        "        if neg_found:\n",
        "            modifier *= -0.74   # VADER aplica un factor de inversión aproximado (didáctico)\n",
        "            notes.append(\"negation\")\n",
        "\n",
        "        # mayúsculas (énfasis)\n",
        "        if caps_emphasis(tokens[i]):\n",
        "            modifier *= 1.5\n",
        "            notes.append(\"ALLCAPS\")\n",
        "\n",
        "        # puntuación de énfasis: exclamaciones en el texto aumentan (global)\n",
        "        exclamations = text.count(\"!\")\n",
        "        if exclamations > 0:\n",
        "            # factor ligero por exclamaciones (didáctico)\n",
        "            modifier *= (1 + 0.05 * min(exclamations, 4))\n",
        "            notes.append(f\"exclaim({exclamations})\")\n",
        "\n",
        "        # calcular adjusted score: base * modifier\n",
        "        adj = base * modifier if found else 0.0\n",
        "\n",
        "        infos.append(TokenInfo(token=tok, found=found, base_score=base, modifier=modifier, adjusted_score=adj, notes=\", \".join(notes)))\n",
        "\n",
        "    # regla contrastiva (pero / but): dar mayor peso a lo posterior a \"but\"/\"pero\"\n",
        "    # estrategia didáctica: si se encuentra 'but' o 'pero', multiplica por 1.5 los scores posteriores\n",
        "\n",
        "    for i, info in enumerate(infos):\n",
        "        if info.token.lower() in CONTRASTIVE:\n",
        "            # aplicar factor a los tokens posteriores hasta final\n",
        "            for k in range(i+1, len(infos)):\n",
        "                if infos[k].found:\n",
        "                    new_adj = infos[k].adjusted_score * 1.5\n",
        "                    infos[k] = infos[k]._replace(adjusted_score=new_adj, notes=(infos[k].notes + \", contrastive\" if infos[k].notes else \"contrastive\"))\n",
        "\n",
        "    # ahora sumamos los adjusted_score y aplicamos fórmula compound\n",
        "    adjusted_scores = [inf.adjusted_score for inf in infos]\n",
        "\n",
        "    # obtener manual sum only of non-zero\n",
        "    sum_adjusted = sum(adjusted_scores)\n",
        "    compound_manual = compute_compound_from_list(adjusted_scores)\n",
        "\n",
        "    # obtener VADER analyzer compound (para comparar)\n",
        "    try:\n",
        "        vader_scores = analyzer.polarity_scores(text)\n",
        "        compound_analyzer = vader_scores.get(\"compound\", None)\n",
        "    except Exception:\n",
        "        compound_analyzer = None\n",
        "\n",
        "    if show_details:\n",
        "        # mostrar tabla\n",
        "        print(f\"Texto: {text}\\n\")\n",
        "        print(f\"{'token':15s} {'found':7s} {'base':8s} {'modifier':9s} {'adj':8s}  notes\")\n",
        "        print(\"-\"*80)\n",
        "        for inf in infos:\n",
        "            base_s = f\"{inf.base_score:.3f}\" if inf.found else \"---\"\n",
        "            mod_s = f\"{inf.modifier:.3f}\"\n",
        "            adj_s = f\"{inf.adjusted_score:.3f}\"\n",
        "            print(f\"{inf.token:15s} {str(inf.found):7s} {base_s:8s} {mod_s:9s} {adj_s:8s}  {inf.notes}\")\n",
        "        print(\"-\"*80)\n",
        "        print(f\"Sum adjusted scores: {sum_adjusted:.3f}\")\n",
        "        print(f\"Compound (manual formula): {compound_manual:.4f}\")\n",
        "        print(f\"Compound (analyzer.polarity_scores): {compound_analyzer}\\n\")\n",
        "\n",
        "                # === MOSTRAR NEG / NEU / POS justo debajo ===\n",
        "        if vader_scores:\n",
        "            print(\"VADER breakdown\")\n",
        "            print(f\"  NEG: {vader_scores['neg']:.3f}\")\n",
        "            print(f\"  NEU: {vader_scores['neu']:.3f}\")\n",
        "            print(f\"  POS: {vader_scores['pos']:.3f}\")\n",
        "            print(\"-\"*80 + \"\\n\")\n",
        "\n",
        "\n",
        "    return infos, sum_adjusted, compound_manual, compound_analyzer\n"
      ],
      "metadata": {
        "id": "3kMzf_Do2rId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Obtener POS, NEG, NEU y compound para cada texto ===\n",
        "\n",
        "textos = {\"texto1\": texto1, \"texto2\": texto2, \"texto3\": texto3, \"texto4\": texto4, \"texto5\": texto5}\n",
        "print(\"\\n=== Resultados VADER: NEG / NEU / POS / COMPOUND ===\\n\")\n",
        "\n",
        "for nombre, txt in textos.items():\n",
        "    scores = analyzer.polarity_scores(txt)\n",
        "\n",
        "    # le decimos de imprimir el nombre del texto y (si necesario) el contenido texto mismo {txt}\n",
        "    print(f\"{nombre}: \\n{txt}\")\n",
        "    print(f\"  NEG: {scores['neg']:.3f}\")\n",
        "    print(f\"  NEU: {scores['neu']:.3f}\")\n",
        "    print(f\"  POS: {scores['pos']:.3f}\")\n",
        "    print(f\"  COMPOUND: {scores['compound']:.4f}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "V99XdzTqn8_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Experimento con textos en español**"
      ],
      "metadata": {
        "id": "lMvoAZ6IO13Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejecutar resultados del pipeline\n",
        "vader_stepwise(texto1)"
      ],
      "metadata": {
        "id": "KNAD8_Nc4wCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejecutar resultados del pipeline\n",
        "vader_stepwise(texto2)"
      ],
      "metadata": {
        "id": "GKHXqb2C7N9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Experimento con textos en inglés**"
      ],
      "metadata": {
        "id": "byeI07w3PCEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejecutar resultados del pipeline\n",
        "vader_stepwise(texto3)"
      ],
      "metadata": {
        "id": "-ImzNJ_x7cbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejecutar resultados del pipeline\n",
        "vader_stepwise(texto4)"
      ],
      "metadata": {
        "id": "MwdQWNYnF4xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejecutar resultados del pipeline\n",
        "vader_stepwise(texto5)"
      ],
      "metadata": {
        "id": "rKRtRiaf8EP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Observaciones y explicaciones:** usando el ejemplo del ***texto5***:\n",
        "\n",
        "  ***\"OMG, OH MY GOD !!! The wait was TOO LONG and the food arrived cold. The service was careless and the overall experience was quite disappointing, but my kids love it.\"***\n",
        "\n",
        "- Los signos “**!**” y otros signos y palabras → “**found = False**”\n",
        "  - NO significa que “VADER no los reconozca”\n",
        "  - significa que **no está** en el ***lexicon*** de **palabras con sentimiento**\n",
        "  - =>  **no aportan sentimiento propio** → base = 0 y adjusted = 0\n",
        "  - Sí que **las reconoce** y pueden acaban **afectando el cálculo final** ('interpretación') **si afectan el modifier**\n",
        "\n",
        "### **Exclamation (!)**\n",
        "\n",
        "En la tabla resultante siempre **aparece 1.15 cuando hay un “nivel bajo” de excitación** aplicando así este valor moderado (≈ +15%) cuando no hay refuerzo especial ni palabras en mayúsculas.\n",
        "\n",
        "VADER aumenta la intensidad según cuántos “!” encuentre (máx. 4):\n",
        "\n",
        "- Luego, cada '**!**' suma → +0.292\n",
        "- si hay 4 -> +0.292 x 4 = 1,168\n",
        "\n",
        "#### **QUÉ ES “modifier”**\n",
        "  \n",
        "  - modifier refleja el **estado de intensidad acumulado**, el **factor multiplicador final** que se aplica al *base_score* de cada *token* con **sentimiento**, que luego se aplicaría a la **siguiente palabra con sentimiento**, si existiera\n",
        "\n",
        "### **QUÉ son los Booster words (intensificadores/atenuadores)**\n",
        "\n",
        "  - Ej.: very, extremely, quite, barely…\n",
        "Modifican ±10% o ±15% el valor de la palabra a la derecha.\n",
        "\n",
        "    quite → +0.15 sobre palabras positivas\n",
        "\n",
        "    quite → −0.15 sobre palabras negativas\n",
        "\n",
        "    => cuando aparece “quite” antes de disappointing se aplica: modifier = 1 + 0.15 = 1.15\n",
        "\n",
        "    => si hay signos de exclamación (!), se suma más\n",
        "\n",
        "  - Ejemplo:\n",
        "\n",
        "    **El resultado !     False   --->   1.150 ->  0.000 ->  exclaim(3) Significa:**\n",
        "\n",
        "    - found=False → “!” no es una palabra del léxico emocional, pero contará como amplificador.\n",
        "\n",
        "    - modifier=1.150 → los signos de exclamación están amplificando el sentimiento de palabras cercanas.\n",
        "\n",
        "    - adjusted_score=0.000 → al no tener base_score, ellos solos no suman ni restan.\n",
        "\n",
        "    - exclaim(3) → se detectaron 3 signos “!”, y VADER eleva la excitación general del texto.\n",
        "\n",
        "### **QUÉ son ALL CAPS (*capital letters* - todo mayúsculas)**\n",
        "\n",
        "  - Ej.: OMG, OH, MY, TOO, LONG\n",
        "\n",
        "Veamos la línea:\n",
        "\n",
        "TokenInfo(token='**GOD**', found=True, base_score=1.1, modifier=1.7249, adjusted_score=1.8975, notes='lexicon, ALLCAPS, exclaim(3)'\n",
        "\n",
        "- “OMG, OH, MY” no están en el léxico → no suman nada\n",
        "\n",
        "- Pero sí reciben modifiers (mayúsculas, exclamaciones), aunque multiplican 0 → 0.\n",
        "\n",
        "- El único término que contribuye a la emoción de ese bloque es *GOD*, por eso genera una 'positividad artificial'.\n",
        "\n",
        "\n",
        "  - Ej.: POR QUÉ \"**OMG** / **OH MY GOD**\" dispara valores raros\n",
        "\n",
        "    - “**GOD**” está en el **léxico como positivo** (valor base +1.1)\n",
        "\n",
        "    - Está en mayúsculas → se refuerza modifier => modifier + 0.733 (≈ **+73% de intensidad**)\n",
        "\n",
        "    - Va seguido de “!!!” → se refuerza más\n",
        "    - Los modifiers de *GOD* son 1.725 (≈ 1 + 0.733).\n",
        "\n",
        "\n",
        "    - **¿Cuál es el peso total del token “GOD” en este texto**?\n",
        "\n",
        "      +1.10 → sentimiento base en el léxico\n",
        "\n",
        "      ×1.725 → amplificación por mayúsculas y signos de exclamación\n",
        "\n",
        "      = 1.10 × 1.725 = 1.8975\n",
        "\n",
        "      = 1.90 → puntuación final ajustada (positivo artificial)\n",
        "\n",
        "\n",
        "### **Contrast (“but”, “however”)**\n",
        "\n",
        "- Cuando aparece “but”, VADER reduce la intensidad del sentimiento de la parte antes de “but” (*pero*)\n",
        "\n",
        "- aumenta la intensidad de lo que está después\n",
        "\n",
        "- Eso explica por qué ***love recibe “contrastive***”.\n",
        "\n",
        "- Por eso love termina con modifier 1.15 pero su efecto domina en el compound final\n",
        "\n",
        "Veamos la línea :\n",
        "\n",
        "TokenInfo(token='**love**', found=**True**, **base_score=3.2**, **modifier=1.15**, **adjusted_score=5.52**, **notes**='lexicon, exclaim(3), contrastive\n",
        "\n",
        "  -   podemos calcular 3.2 * 1.15 = 3.68 (no 5.520 !) -> Esto solo aplica el modifier local (mayúsculas, exclamaciones, boosters)\n",
        "  - falta un paso más del algoritmo:\n",
        "    - aplicar el “**contrastive shift**” por ***BUT*** (“***Pseudorule of contrastive conjunctions***”)\n",
        "      - VADER **reduce el peso de los sentimientos anteriores** y **aumenta el sentimiento posterior** aproximadamente x1.5, por lo que tendremos:\n",
        "      - **base_score** x **modifier** x **contrastive boost** = **adjusted_score** (peso real de la palabra)\n",
        "\n",
        "        \n",
        "      - Con ello vemos que aumenta el peso del sentimiento que viene después del “but”\n",
        "\n",
        "    - ¿Cuál es el peso total del **token “love”** en **este texto**?\n",
        "\n",
        "        3.20 → sentimiento base de “love” en el léxico\n",
        "\n",
        "        ×1.15 → amplificación por contexto (mayúsculas, exclamación, etc.)\n",
        "\n",
        "        ×1.50 → boost adicional porque viene después de “but” (regla contrastiva)\n",
        "\n",
        "      = 3.2 × 1.15 × 1.5 = 5.52  \n",
        "      \n",
        "      = 5.52 → puntuación final ajustada\n",
        "\n",
        "Su peso es 5.52, dominando el análisis porque aparece después de “but”,\n",
        "y VADER está **diseñado para priorizar “la cláusula final”** en frases **contrastivas** siendo una **regla lingüística preprogramada** del inglés, si tenemos “It was bad, but I loved it” → **el sentimiento final domina**, no siendo solo un matiz.\n",
        "\n",
        "### **RESUMEN DE REGLAS AFECTANDO AL CÁLCULO GENERAL**\n",
        "\n",
        "**modifier** de las palabras => **combinación de**:\n",
        "\n",
        "- Booster words\n",
        "- ALL CAPS\n",
        "- Exclamation\n",
        "- Reglas de contraste (“but”, \"however\")\n",
        "- Negación (no aparece en este texto, pero podrá ser \"***not***\" como en \"***not nice***\")\n",
        "- Algunas otras reglas y matices\n"
      ],
      "metadata": {
        "id": "q2yH7ScRIptG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Algunas visualizaciones de los resultados**"
      ],
      "metadata": {
        "id": "W2JgBImcaV7L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A continuación mostramos unas gráficas con los textos más positivos, negativos o neutros.\n",
        "- Demostrar cómo VADER cambia mucho según el idioma, o una frase contrastiva como “but my kids love it”."
      ],
      "metadata": {
        "id": "nRs2drPcQTa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame([\n",
        "    {\"texto\": \"texto1\", **analyzer.polarity_scores(texto1)},\n",
        "    {\"texto\": \"texto2\", **analyzer.polarity_scores(texto2)},\n",
        "    {\"texto\": \"texto3\", **analyzer.polarity_scores(texto3)},\n",
        "    {\"texto\": \"texto4\", **analyzer.polarity_scores(texto4)},\n",
        "    {\"texto\": \"texto5\", **analyzer.polarity_scores(texto5)},\n",
        "])\n",
        "\n",
        "df_melt = df.melt(id_vars=\"texto\", value_vars=[\"pos\", \"neg\", \"neu\"])\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(data=df_melt, x=\"texto\", y=\"value\", hue=\"variable\")\n",
        "plt.title(\"Comparación POS / NEG / NEU por texto\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7m9CWT25QEfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Lo mismo pero con el valor \"compound\" de cada texto"
      ],
      "metadata": {
        "id": "c2AWdlZ0Zqw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Orden consistente\n",
        "orden = df[\"texto\"].tolist()\n",
        "\n",
        "# Melt para barras (pos/neg/neu)\n",
        "df_melt = df.melt(id_vars=\"texto\", value_vars=[\"pos\", \"neg\", \"neu\"], var_name=\"sent_type\", value_name=\"value\")\n",
        "\n",
        "# Configurar figura\n",
        "plt.figure(figsize=(10,6))\n",
        "ax = plt.gca()\n",
        "\n",
        "# Barras POS/NEG/NEU\n",
        "sns.barplot(data=df_melt, x=\"texto\", y=\"value\", hue=\"sent_type\", order=orden, ax=ax)\n",
        "\n",
        "# Añadir eje secundario para compound\n",
        "ax2 = ax.twinx()\n",
        "x_positions = np.arange(len(orden))\n",
        "\n",
        "# Tomar compounds en el mismo orden\n",
        "compounds = df.set_index(\"texto\").loc[orden, \"compound\"].values\n",
        "\n",
        "# Dibujar línea y markers para compound (eje derecho)\n",
        "ax2.plot(x_positions, compounds, color=\"white\", marker=\"o\", linestyle='-', linewidth=3, label=\"compound\")\n",
        "ax2.set_ylim(-1.05, 1.05)\n",
        "ax2.set_ylabel(\"Compound (VADER)\")\n",
        "\n",
        "# Ajustes estéticos\n",
        "ax.set_title(\"Comparación POS / NEG / NEU por texto — con compound\")\n",
        "ax.set_ylabel(\"Proporción (pos/neg/neu)\")\n",
        "ax.set_xlabel(\"\")\n",
        "ax.set_xticklabels(orden)\n",
        "ax.legend(loc=\"upper left\")\n",
        "ax2.legend(loc=\"upper right\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "AstkG18mYIXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Solo columnas de interés\n",
        "variables = [\"pos\", \"neg\", \"neu\"]\n",
        "\n",
        "# Configurar figura: 2 filas × 3 columnas (uno queda vacío)\n",
        "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
        "axes = axes.flatten()\n",
        "\n",
        "colors = [\"#66c2a5\", \"#fc8d62\", \"#8da0cb\"]   # verde, rojo, azul suave\n",
        "\n",
        "for i, (idx, row) in enumerate(df.iterrows()):\n",
        "    ax = axes[i]\n",
        "    valores = [row[v] for v in variables]\n",
        "\n",
        "    ax.pie(\n",
        "        valores,\n",
        "        labels=variables,\n",
        "        autopct='%1.1f%%',\n",
        "        startangle=90,\n",
        "        colors=colors\n",
        "    )\n",
        "    ax.set_title(row[\"texto\"], fontsize=12)\n",
        "\n",
        "# El último subplot queda vacío → lo apagamos\n",
        "axes[-1].axis(\"off\")\n",
        "\n",
        "plt.suptitle(\"Distribución POS / NEG / NEU por texto\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PQrsR6w3dUTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Mostramos las **palabras / tokens qué más influyen** en el dagnóstico de cada texto analizado"
      ],
      "metadata": {
        "id": "tbJvsmisZMKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Parámetros globales\n",
        "Y_MIN, Y_MAX = -6, 6        # Escala vertical común\n",
        "WIDTH_PER_BAR = 0.7         # ancho base por barra\n",
        "MIN_WIDTH = 6               # ancho mínimo para evitar gráficos demasiado pequeños\n",
        "\n",
        "textos = {\n",
        "    \"texto1\": texto1,\n",
        "    \"texto2\": texto2,\n",
        "    \"texto3\": texto3,\n",
        "    \"texto4\": texto4,\n",
        "    \"texto5\": texto5,\n",
        "}\n",
        "\n",
        "for nombre, contenido in textos.items():\n",
        "    infos, _, _, _ = vader_stepwise(contenido, show_details=False)\n",
        "\n",
        "    df_tok = pd.DataFrame([\n",
        "        {\"token\": inf.token, \"score\": inf.adjusted_score}\n",
        "        for inf in infos\n",
        "        if inf.adjusted_score != 0\n",
        "    ])\n",
        "\n",
        "    if df_tok.empty:\n",
        "        print(f\"(Aviso) {nombre}: no hay tokens con adjusted_score != 0 → gráfico omitido.\\n\")\n",
        "        continue\n",
        "\n",
        "    # --- ORDENAR por adjusted_score ---\n",
        "    df_tok = df_tok.sort_values(\"score\", ascending=True)   # <<< CAMBIAR ascending=False para DESCENDENTE\n",
        "\n",
        "    # --- Ajustar tamaño horizontal según nº de barras ---\n",
        "    num_barras = len(df_tok)\n",
        "    fig_width = max(MIN_WIDTH, num_barras * WIDTH_PER_BAR)\n",
        "\n",
        "    plt.figure(figsize=(fig_width, 4))\n",
        "    sns.barplot(data=df_tok, x=\"token\", y=\"score\")\n",
        "\n",
        "    plt.ylim(Y_MIN, Y_MAX)  # escala vertical común\n",
        "    plt.title(f\"Contribución por token al sentimiento – {nombre}\")\n",
        "    plt.xticks(rotation=60)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "LBxAsygLW5-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Radial plot de los tokens con algún peso sentimental**"
      ],
      "metadata": {
        "id": "Za4a6y2rkFe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener datos de adjusted_score sin imprimir tablas\n",
        "infos1, _, _, _ = vader_stepwise(texto1, show_details=False)\n",
        "infos2, _, _, _ = vader_stepwise(texto2, show_details=False)\n",
        "infos3, _, _, _ = vader_stepwise(texto3, show_details=False)\n",
        "infos4, _, _, _ = vader_stepwise(texto4, show_details=False)\n",
        "infos5, _, _, _ = vader_stepwise(texto5, show_details=False)\n",
        "\n",
        "# Convertir a diccionario token → score\n",
        "def dict_from_infos(infos):\n",
        "    return {inf.token: inf.adjusted_score for inf in infos if inf.adjusted_score != 0}\n",
        "\n",
        "d1 = dict_from_infos(infos1)\n",
        "d2 = dict_from_infos(infos2)\n",
        "d3 = dict_from_infos(infos3)\n",
        "d4 = dict_from_infos(infos4)\n",
        "d5 = dict_from_infos(infos5)\n",
        "\n",
        "# Conjunto total de tokens relevantes\n",
        "all_tokens = sorted(set(d1)|set(d2)|set(d3)|set(d4)|set(d5))\n",
        "\n",
        "# Crear dataframe tokens × textos\n",
        "df = pd.DataFrame({\n",
        "    \"token\": all_tokens,\n",
        "    \"texto1\": [d1.get(t, 0) for t in all_tokens],\n",
        "    \"texto2\": [d2.get(t, 0) for t in all_tokens],\n",
        "    \"texto3\": [d3.get(t, 0) for t in all_tokens],\n",
        "    \"texto4\": [d4.get(t, 0) for t in all_tokens],\n",
        "    \"texto5\": [d5.get(t, 0) for t in all_tokens],\n",
        "})\n",
        "\n",
        "df = df.set_index(\"token\")\n",
        "\n",
        "# ----- R A D A R   C H A R T -----\n",
        "\n",
        "labels = df.index.tolist()\n",
        "num_vars = len(labels)\n",
        "\n",
        "# Ángulos para el radar chart\n",
        "angles = np.linspace(0, 2*np.pi, num_vars, endpoint=False).tolist()\n",
        "angles += angles[:1]  # cerrar círculo\n",
        "\n",
        "# Crear figura\n",
        "plt.figure(figsize=(10, 10))\n",
        "ax = plt.subplot(111, polar=True)\n",
        "\n",
        "# Colores seaborn\n",
        "colors = sns.color_palette(\"husl\", 5)\n",
        "\n",
        "# Función para trazar cada texto\n",
        "def add_radar(values, label, color):\n",
        "    vals = values.tolist()\n",
        "    vals += vals[:1]  # cerrar forma\n",
        "    ax.plot(angles, vals, linewidth=1, label=label, color=color)\n",
        "    ax.fill(angles, vals, alpha=0.15, color=color)\n",
        "\n",
        "# Agregar líneas para cada texto\n",
        "add_radar(df[\"texto1\"], \"Texto 1\", colors[0])\n",
        "add_radar(df[\"texto2\"], \"Texto 2\", colors[1])\n",
        "add_radar(df[\"texto3\"], \"Texto 3\", colors[2])\n",
        "add_radar(df[\"texto4\"], \"Texto 4\", colors[3])\n",
        "add_radar(df[\"texto5\"], \"Texto 5\", colors[4])\n",
        "\n",
        "# Etiquetas en el borde\n",
        "ax.set_xticks(angles[:-1])\n",
        "ax.set_xticklabels(labels, fontsize=12)\n",
        "\n",
        "# Rango uniforme para todos\n",
        "ax.set_ylim(min(df.min()) - 0.5, max(df.max()) + 0.5)\n",
        "\n",
        "# Título\n",
        "# plt.title(\"Radar Chart – Tokens y adjusted_score por texto\", fontsize=16)\n",
        "plt.title(\"Radar Chart – Tokens y adjusted_score por texto\", fontsize=16, pad=40)\n",
        "plt.subplots_adjust(top=0.80)\n",
        "\n",
        "# Leyenda\n",
        "plt.legend(loc=\"upper right\", bbox_to_anchor=(1.25, 1.1))\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Z385oehZg4jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusiones\n",
        "\n",
        "Hemos visto cómo convertir texto en datos, cómo limpiarlo, visualizarlo y analizar su sentimiento.  \n",
        "También vimos cómo las máquinas interpretan la estructura del lenguaje.\n",
        "\n",
        "Este cuaderno muestra un flujo básico para análisis exploratorio de texto:  \n",
        "desde tokenización y frecuencias hasta sentimiento y relaciones entre textos.\n",
        "\n",
        "Estos métodos son útiles para:\n",
        "- reseñas  \n",
        "- encuestas abiertas  \n",
        "- análisis de redes sociales  \n",
        "- análisis de artículos o noticias  \n",
        "- comparaciones entre documentos  \n"
      ],
      "metadata": {
        "id": "VSQFfMykt0zd"
      }
    }
  ]
}